<!DOCTYPE html><html lang="en" data-reactroot=""><head><title>Using Vision in Real Time with ARKit | Apple Developer Documentation</title><meta content="width=device-width, initial-scale=1 viewport-fit=cover" name="viewport"/><meta data-pid="310635"/><link href="https://www.apple.com/wss/fonts?families=SF+Pro,v1|SF+Mono,v1|SF+Pro+Icons,v1" media="all" rel="stylesheet" type="text/css"/><link href="/documentation/__assets/application-e5bb1544.css" media="all" rel="stylesheet" type="text/css"/><noscript><link href="/documentation/__assets/nojs-c6be9131.css" media="all" rel="stylesheet" type="text/css"/></noscript><link rel="mask-icon" href="/documentation/__assets/apple-logo.svg" color="#000"/><link rel="shortcut icon" href="/documentation/__assets/favicon.ico"/><script src="/documentation/__assets/shared-570ae4d6.js"></script><script id="init-data" type="application/json">{"variant":{"paths":["documentation\/arkit\/using_vision_in_real_time_with_arkit"]}}</script><script src="/documentation/__assets/init-be6d8150.js"></script></head><body><div id="_omniture_top">
      <script>
        var s_account="awdappledeveloper"
      </script>
      <script src="https://developer.apple.com/assets/metrics/scripts/analytics.js"></script>
      <script>
        s.pageName= AC && AC.Tracking && AC.Tracking.pageName();
        s.channel="www.documentation.developer"

        var s_code=s.t();if(s_code)document.write(s_code)
      </script>
    </div><div id="app"><div><a href="#main" id="skip-localnav" class="showonfocus hidden">Skip Navigation</a><aside id="ac-gn-segmentbar" class="ac-gn-segmentbar" lang="en-US" dir="ltr"></aside><input type="checkbox" id="ac-gn-menustate" class="ac-gn-menustate"/><nav id="ac-globalnav" class="no-js" role="navigation" aria-label="Global" data-hires="false" data-analytics-region="global nav" lang="en-US" dir="ltr" data-store-locale="us" data-store-api="/[storefront]/shop/bag/status" data-search-locale="en_US" data-search-api="/search-services/suggestions/">
      <div class="ac-gn-content">
        <ul class="ac-gn-header">
          <li class="ac-gn-item ac-gn-menuicon">
            <label class="ac-gn-menuicon-label" for="ac-gn-menustate" aria-hidden="true">
              <span class="ac-gn-menuicon-bread ac-gn-menuicon-bread-top">
                <span class="ac-gn-menuicon-bread-crust ac-gn-menuicon-bread-crust-top"></span>
              </span>
              <span class="ac-gn-menuicon-bread ac-gn-menuicon-bread-bottom">
                <span class="ac-gn-menuicon-bread-crust ac-gn-menuicon-bread-crust-bottom"></span>
              </span>
            </label>
            <a href="#ac-gn-menustate" role="button" class="ac-gn-menuanchor ac-gn-menuanchor-open" id="ac-gn-menuanchor-open">
              <span class="ac-gn-menuanchor-label">Global Nav Open Menu</span>
            </a>
            <a href="#" role="button" class="ac-gn-menuanchor ac-gn-menuanchor-close" id="ac-gn-menuanchor-close">
              <span class="ac-gn-menuanchor-label">Global Nav Close Menu</span>
            </a>
          </li>
          <li class="ac-gn-item ac-gn-apple">
            <a class="ac-gn-link ac-gn-link-apple-developer" href="/" data-analytics-title="appledeveloper home" id="ac-gn-firstfocus-small">
              <span class="ac-gn-link-text">Apple Developer</span>
            </a>
          </li>
        </ul>
        <div class="ac-gn-search-placeholder-container" role="search">
          <div class="ac-gn-search ac-gn-search-small">
            <a id="ac-gn-link-search-small" class="ac-gn-link" href="/search/" data-analytics-title="search" data-analytics-click="search" data-analytics-intrapage-link aria-label="Search Developer">
              <div class="ac-gn-search-placeholder-bar">
                <div class="ac-gn-search-placeholder-input">
                  <div class="ac-gn-search-placeholder-input-text" aria-hidden="true">
                    <div class="ac-gn-link-search ac-gn-search-placeholder-input-icon"></div>
                    <span class="ac-gn-search-placeholder">Search Developer</span>
                  </div>
                </div>
                <div class="ac-gn-searchview-close ac-gn-searchview-close-small ac-gn-search-placeholder-searchview-close">
                  <span class="ac-gn-searchview-close-cancel" aria-hidden="true">Cancel</span>
                </div>
              </div>
            </a>
          </div>
        </div>
        <ul class="ac-gn-list">
          <li class="ac-gn-item ac-gn-apple">
            <a class="ac-gn-link ac-gn-link-apple-developer" href="/" data-analytics-title="appledeveloper home" id="ac-gn-firstfocus">
              <span class="ac-gn-link-text">Apple Developer</span>
              </a>
          </li>
          <li class="ac-gn-item ac-gn-item-menu ac-gn-discover">
            <a class="ac-gn-link ac-gn-link-discover" href="/discover/" data-analytics-title="discover">
              <span class="ac-gn-link-text">Discover</span>
              </a>
          </li>
          <li class="ac-gn-item ac-gn-item-menu ac-gn-design">
            <a class="ac-gn-link ac-gn-link-design" href="/design/" data-analytics-title="design">
              <span class="ac-gn-link-text">Design</span>
              </a>
          </li>
          <li class="ac-gn-item ac-gn-item-menu ac-gn-develop">
            <a class="ac-gn-link ac-gn-link-develop" href="/develop/" data-analytics-title="develop">
              <span class="ac-gn-link-text">Develop</span>
              </a>
          </li>
          <li class="ac-gn-item ac-gn-item-menu ac-gn-distribute">
            <a class="ac-gn-link ac-gn-link-distribute" href="/distribute/" data-analytics-title="distribute">
              <span class="ac-gn-link-text">Distribute</span>
              </a>
          </li>
          <li class="ac-gn-item ac-gn-item-menu ac-gn-dsupport">
            <a class="ac-gn-link ac-gn-link-dsupport" href="/support/" data-analytics-title="dsupport">
              <span class="ac-gn-link-text">Support</span>
              </a>
          </li>
          <li class="ac-gn-item ac-gn-item-menu ac-gn-account">
            <a class="ac-gn-link ac-gn-link-account" href="/account/" data-analytics-title="account">
              <span class="ac-gn-link-text">Account</span>
              </a>
          </li>
          <li class="ac-gn-item ac-gn-item-menu ac-gn-search" role="search">
            <a id="ac-gn-link-search" class="ac-gn-link ac-gn-link-search" href="/search/" data-analytics-title="search" data-analytics-click="search" data-analytics-intrapage-link aria-label="Search Developer"></a>
          </li>
        </ul>
        <aside id="ac-gn-searchview" class="ac-gn-searchview" role="search" data-analytics-region="search">
          <div class="ac-gn-searchview-content">
            <div class="ac-gn-searchview-bar">
              <div class="ac-gn-searchview-bar-wrapper">
                <form id="ac-gn-searchform" class="ac-gn-searchform" action="/search/" method="get">
                  <div class="ac-gn-searchform-wrapper">
                    <input id="ac-gn-searchform-input" class="ac-gn-searchform-input" type="text" name="q" aria-label="Search Developer" placeholder="Search Developer" autocorrect="off" autocapitalize="off" autocomplete="off" spellcheck="false" role="combobox" aria-autocomplete="list" aria-expanded="true" aria-owns="quicklinks suggestions" />
                    <button id="ac-gn-searchform-submit" class="ac-gn-searchform-submit" type="submit" disabled aria-label="Submit Search"></button>
                    <button id="ac-gn-searchform-reset" class="ac-gn-searchform-reset" type="reset" disabled aria-label="Clear Search">
                        <span class="ac-gn-searchform-reset-background"></span>
                      </button>
                  </div>
                </form>
                <button id="ac-gn-searchview-close-small" class="ac-gn-searchview-close ac-gn-searchview-close-small" aria-label="Cancel Search">
                    <span class="ac-gn-searchview-close-cancel" aria-hidden="true">
                      Cancel
                    </span>
                  </button>
              </div>
            </div>
            <aside id="ac-gn-searchresults" class="ac-gn-searchresults" data-string-quicklinks="Quick Links" data-string-suggestions="Suggested Searches" data-string-noresults=""></aside>
          </div>
          <button id="ac-gn-searchview-close" class="ac-gn-searchview-close" aria-label="Cancel Search">
              <span class="ac-gn-searchview-close-wrapper">
                <span class="ac-gn-searchview-close-left"></span>
                <span class="ac-gn-searchview-close-right"></span>
              </span>
            </button>
        </aside>
          </div>
    </nav><div class="ac-gn-blur"></div><div id="ac-gn-curtain" class="ac-gn-curtain"></div><div id="ac-gn-placeholder" class="ac-nav-placeholder"></div><input type="checkbox" id="localnav-menustate" class="localnav-menustate" aria-hidden="true"/><nav id="localnav" class="localnav localnav-dark theme-dark localnav-scrim localnav-noborder" role="navigation" aria-label="API Reference" data-sticky="true"><div class="localnav-wrapper"><div class="referencenav"><div class="localnav-background"></div><div class="localnav-content"><a href="/documentation" class="localnav-title">Documentation</a><div class="localnav-menu"><a href="#localnav-menustate" id="localnav-menustate-open" class="localnav-menucta-anchor localnav-menucta-anchor-open"><span class="localnav-menucta-anchor-label" aria-hidden="true">Open Menu</span></a><a href="#" id="localnav-menustate-close" class="localnav-menucta-anchor localnav-menucta-anchor-close"><span class="localnav-menucta-anchor-label" aria-hidden="true">Close Menu</span></a><div class="localnav-menu-tray"><ul aria-label="Breadcrumbs" class="localnav-menu-items localnav-menu-breadcrumbs"><li class="localnav-menu-item localnav-menu-breadcrumb-item"><a class="localnav-menu-link" href="/documentation/arkit">ARKit</a></li><li class="localnav-menu-item localnav-menu-breadcrumb-item"><div class="localnav-menu-breadcrumb-current-container localnav-menu-link current"><span aria-current="page" class="localnav-menu-breadcrumb-current">Using Vision in Real Time with ARKit</span></div></li></ul><ul class="localnav-menu-items localnav-menu-settings" data-breadcrumbs-count="2"><li class="localnav-menu-setting language-container"><div class="language-toggle-container"><label for="language-toggle" class="language-toggle-label">Language:</label><select id="language-toggle" class="language-dropdown localnav-menu-link" style="width:auto"><option selected="" value="swift">Swift</option><option value="occ">Objective-C</option></select></div><div class="language-list-container"><span class="localnav-menu-setting-label">Language:</span><ul class="language-list"><li class="language-list-item"><span data-language="swift" aria-current="page" class="current-language">Swift</span></li><li class="language-list-item"><a href="/documentation/arkit/using_vision_in_real_time_with_arkit?language=objc" class="localnav-menu-setting-link">Objective-C</a></li></ul></div></li><li class="localnav-menu-setting"><span class="localnav-menu-setting-label">API Changes:</span><span class="changes-toggle">None</span></li></ul></div><div class="localnav-actions"><div class="localnav-action localnav-action-menucta" aria-hidden="true"><label for="localnav-menustate" class="localnav-menucta"><span class="localnav-menucta-chevron"></span></label></div></div></div></div></div></div></nav><label for="localnav-menustate" id="localnav-curtain" aria-hidden="true"></label><main role="main" id="main" class="main" tabindex="0"><div class="topic-title"><span class="eyebrow">Sample Code</span><h1 class="topic-heading"><span>Using Vision in Real Time with ARKit</span></h1></div><div class="topic-container section-content row"><div class="topic-description column large-9 medium-9 small-12"><div class="topic-abstract abstract formatted-content"><div><p>Manage Vision resources for efficient execution of a Core ML image classifier, and use SpriteKit to display image classifier output in AR.</p></div></div><a href="https://docs-assets.developer.apple.com/published/7da9756a21/UsingVisionInRealTimeWithARKit.zip" download="" class="downloadsample"><span class="button" aria-label="Download sample code">Download</span></a></div><div class="topic-summary column large-3 medium-3 small-12"><div class="topic-summary-section sdks" role="complementary" aria-label="SDKs"><p class="topic-summary-section-label subsection-label">SDKs</p><ul class="topic-summary-section-list"><li class="topic-summary-section-item sdk"><span aria-label="iOS 11.3+, Available on iOS 11.3 and later" role="text" title="Available on iOS 11.3 and later">iOS 11.3+</span></li><li class="topic-summary-section-item sdk"><span aria-label="Xcode 10.0+, Available on Xcode 10.0 and later" role="text" title="Available on Xcode 10.0 and later">Xcode 10.0+</span></li></ul></div><div class="topic-summary-section frameworks" role="complementary" aria-label="Framework"><p class="topic-summary-section-label subsection-label">Framework</p><ul class="topic-summary-section-list"><li class="topic-summary-section-item"><span>Vision</span></li></ul></div><div class="topic-summary-section onthispage"><nav class="onthispage-nav" aria-labelledby="onthispage-title"><p id="onthispage-title" class="topic-summary-section-label subsection-label">On This Page</p><ul class="topic-summary-section-list"><li class="topic-summary-section-item"><a href="#overview" class="icon icon-after icon-chevrondowncircle">Overview</a></li><li class="topic-summary-section-item"><a href="#see-also" class="icon icon-after icon-chevrondowncircle">See Also</a></li></ul></nav></div></div><div class="topic-content column large-9 medium-9 small-12" id="topic-content"><section id="overview" class="section"><h2>Overview</h2><div class="formatted-content"><div><p>This sample app runs an <a href="/documentation/arkit">ARKit</a> world-tracking session with content displayed in a SpriteKit view. The app uses the <a href="/documentation/vision">Vision</a> framework to pass camera images to a <a href="/documentation/coreml">Core ML</a> classifier model, displaying a label in the corner of the screen to indicate whether the classifier recognizes anything in view of the camera. After the classifier produces a label for the image, the user can tap the screen to place that text in AR world space.</p><aside class="aside aside-note" role="note"><p class="aside-name">Note</p><p>The Core ML image classifier model doesn’t recognize and locate the 3D positions of objects. (In fact, the <code class="code-voice"><span>Inceptionv3</span></code> model attempts only to identify an entire scene.) When the user taps the screen, the app adds a label at a real-world position corresponding to the tapped point. How closely a label appears to relate to the object it names depends on where the user taps.</p></aside></div><h3 id="3007540">Implement the Vision/Core ML Image Classifier</h3><div><p>The sample code’s <code class="code-voice"><span>classification<wbr/>Request</span></code> property, <code class="code-voice"><span>classify<wbr/>Current<wbr/>Image()</span></code> method, and <code class="code-voice"><span>process<wbr/>Classifications(for:<wbr/>error:)</span></code> method manage:</p><ul><li><p>A Core ML image-classifier model, loaded from an <code class="code-voice"><span>mlmodel</span></code> file bundled with the app using the Swift API that Core ML generates for the model</p></li><li><p><a class="symbol-name" href="/documentation/vision/vncoremlrequest"><code><span>VNCore<wbr/>MLRequest</span></code></a> and <a class="symbol-name" href="/documentation/vision/vnimagerequesthandler"><code><span>VNImage<wbr/>Request<wbr/>Handler</span></code></a> objects for passing image data to the model for evaluation</p></li></ul><p>For more details on using <a class="symbol-name" href="/documentation/vision/vnimagerequesthandler"><code><span>VNImage<wbr/>Request<wbr/>Handler</span></code></a>, <a class="symbol-name" href="/documentation/vision/vncoremlrequest"><code><span>VNCore<wbr/>MLRequest</span></code></a>, and image classifier models, see the <a href="/documentation/vision/classifying_images_with_vision_and_core_ml">Classifying Images with Vision and Core ML</a> sample-code project.</p></div><h3 id="3007541">Run the AR Session and Process Camera Images</h3><div><p>The sample <code class="code-voice"><span>View<wbr/>Controller</span></code> class manages the AR session and displays AR overlay content in a SpriteKit view. ARKit captures video frames from the camera and provides them to the view controller in the <a class="symbol-name" href="/documentation/arkit/arsessiondelegate/2865611-session"><code><span>session(_:<wbr/>did<wbr/>Update:)</span></code></a> method, which then calls the <code class="code-voice"><span>classify<wbr/>Current<wbr/>Image()</span></code> method to run the Vision image classifier.</p><figure id="3007531"><div class="formatted-content"><div class="code-listing"><pre class="code-source" data-language="swift"><code>func session(_ session: ARSession, didUpdate frame: ARFrame) {
    // Do not enqueue other buffers for processing while another Vision task is still running.
    // The camera stream has only a finite amount of buffers available; holding too many buffers for analysis would starve the camera.
    guard currentBuffer == nil, case .normal = frame.camera.trackingState else {
        return
    }
    
    // Retain the image buffer for Vision processing.
    self.currentBuffer = frame.capturedImage
    classifyCurrentImage()
}
</code></pre></div></div></figure><p></p></div><h3 id="3007542">Serialize Image Processing for Real-Time Performance</h3><div><p>The <code class="code-voice"><span>classify<wbr/>Current<wbr/>Image()</span></code> method uses the view controller’s <code class="code-voice"><span>current<wbr/>Buffer</span></code> property to track whether Vision is currently processing an image before starting another Vision task.</p><figure id="3007533"><div class="formatted-content"><div class="code-listing"><pre class="code-source" data-language="swift"><code>// Most computer vision tasks are not rotation agnostic so it is important to pass in the orientation of the image with respect to device.
let orientation = CGImagePropertyOrientation(UIDevice.current.orientation)

let requestHandler = VNImageRequestHandler(cvPixelBuffer: currentBuffer!, orientation: orientation)
visionQueue.async {
    do {
        // Release the pixel buffer when done, allowing the next buffer to be processed.
        defer { self.currentBuffer = nil }
        try requestHandler.perform([self.classificationRequest])
    } catch {
        print(&quot;Error: Vision request failed with error \&quot;\(error)\&quot;&quot;)
    }
}
</code></pre></div></div></figure><p></p><aside class="aside aside-important" aria-label="important"><p class="aside-name">Important</p><p>Making sure only one buffer is being processed at a time ensures good performance. The camera recycles a finite pool of pixel buffers, so retaining too many buffers for processing could starve the camera and shut down the capture session. Passing multiple buffers to Vision for processing would slow down processing of each image, adding latency and reducing the amount of CPU and GPU overhead for rendering AR visualizations.</p></aside><p>In addition, the sample app enables the <a class="symbol-name" href="/documentation/vision/vnrequest/2923480-usescpuonly"><code><span>uses<wbr/>CPUOnly</span></code></a> setting for its Vision request, freeing the GPU for use in rendering.</p></div><h3 id="3007543">Visualize Results in AR</h3><div><p>The <code class="code-voice"><span>process<wbr/>Classifications(for:<wbr/>error:)</span></code> method stores the best-match result label produced by the image classifier and displays it in the corner of the screen. The user can then tap in the AR scene to place that label at a real-world position. Placing a label requires two main steps.</p><p>First, a tap gesture recognizer fires the <code class="code-voice"><span>place<wbr/>Label<wbr/>At<wbr/>Location(sender:)</span></code> action. This method uses the ARKit <a class="symbol-name" href="/documentation/arkit/arskview/2875733-hittest"><code><span>hit<wbr/>Test(_:<wbr/>types:)</span></code></a> method to estimate the 3D real-world position corresponding to the tap, and adds an anchor to the AR session at that position.</p><figure id="3007535"><div class="formatted-content"><div class="code-listing"><pre class="code-source" data-language="swift"><code>@IBAction func placeLabelAtLocation(sender: UITapGestureRecognizer) {
    let hitLocationInView = sender.location(in: sceneView)
    let hitTestResults = sceneView.hitTest(hitLocationInView, types: [.featurePoint, .estimatedHorizontalPlane])
    if let result = hitTestResults.first {
        
        // Add a new anchor at the tap location.
        let anchor = ARAnchor(transform: result.worldTransform)
        sceneView.session.add(anchor: anchor)
        
        // Track anchor ID to associate text with the anchor after ARKit creates a corresponding SKNode.
        anchorLabels[anchor.identifier] = identifierString
    }
}
</code></pre></div></div></figure><p></p><p>Next, after ARKit automatically creates a SpriteKit node for the newly added anchor, the <a class="symbol-name" href="/documentation/arkit/arskviewdelegate/2865588-view"><code><span>view(_:<wbr/>did<wbr/>Add:<wbr/>for:)</span></code></a> delegate method provides content for that node. In this case, the sample <code class="code-voice"><span>Template<wbr/>Label<wbr/>Node</span></code> class creates a styled text label using the string provided by the image classifier.</p><figure id="3007536"><div class="formatted-content"><div class="code-listing"><pre class="code-source" data-language="swift"><code>func view(_ view: ARSKView, didAdd node: SKNode, for anchor: ARAnchor) {
    guard let labelText = anchorLabels[anchor.identifier] else {
        fatalError(&quot;missing expected associated label for anchor&quot;)
    }
    let label = TemplateLabelNode(text: labelText)
    node.addChild(label)
}
</code></pre></div></div></figure><p></p></div></div></section></div></div><section id="see-also" class="contenttable section alt-light-container row"><div class="alt-light"><div class="section-content"><h2 class="contenttable-title">See Also</h2><section id="2952384" class="contenttable-section"><div class="contenttable-container row"><div class="contenttable-section-title-container column large-3 medium-3 small-12"><h3 class="contenttable-section-title">Related Technologies</h3></div><div class="contenttable-section-content column large-9 medium-9 small-12"><div class="task-topics"><div class="task-topic"><div class="task-topic-info"><a class="has-adjacent-element symbol-name" href="/documentation/arkit/creating_an_immersive_ar_experience_with_audio"><svg xmlns="http://www.w3.org/2000/svg" height="15" viewBox="0 0 15 15" class="svg-icon symbol-name-icon" aria-hidden="true"><title>Sample Code</title><g class="svg-icon-small" fill-rule="evenodd"><path d="M9 15L9 14 11.0104712 14C11.5759162 14 12.1832461 13.86 12.1832461 12.14L12.1832461 10.28C12.1529524 9.27545906 12.5278004 8.29817424 13.2303665 7.55L13.3246073 7.47C12.5372999 6.72356427 12.1089306 5.6990224 12.1413613 4.64L12.1413613 3.42C12.1413613 3 12.1413613 1 11.0104712 1L9 1 9 0 11.0104712 0C12.3926702 0 13.1884817 1.28 13.1884817 3.42L13.1884817 4.64C13.1884817 6 13.8691099 6.95 14.4764398 6.95L15 6.95 15 7.95 14.4764398 7.95C14.2508552 7.96082278 14.0394061 8.05818375 13.8900524 8.22 13.4104115 8.78359074 13.1611361 9.49421163 13.1884817 10.22L13.1884817 12.09C13.1884817 14 12.4764398 15 11.0104712 15L9 15zM6 15L4.28 15C2.87 15 2 13.85 2 12L2 10.13C2 8.46 1.66 8 .5 8L0 8 0 7 .5 7C1.61 6.95 2 6.3 2 4.49L2 3.27C2 1.32 2.92 0 4.28 0L6 0 6 1 4.28 1C3.4 1 3 2.14 3 3.27L3 4.49C3.11371534 5.55342654 2.78458756 6.61676246 2.09 7.43 2.79401717 8.14117553 3.12990379 9.13776222 3 10.13L3 12C3 12.75 3.17 14 4.29 14L6 14 6 15z"></path></g></svg><span>Creating an Immersive AR Experience with Audio</span></a><div class="task-topic-abstract task-topic-data abstract formatted-content"><div><p>Use sound effects and environmental sound layers to create an engaging AR experience.</p></div></div></div></div></div></div></div></section></div></div></section></main><section id="globalfooter-wrapper"><footer id="globalfooter" role="contentinfo">
        <nav class="footer-breadory">
          <a href="/" class="home breadcrumbs-home"><span aria-hidden="true"></span><span class="breadcrumbs-home-label">Developer</span></a>
          <section class="breadcrumbs">
            <ol class="breadcrumbs-list">
              <li><a href=/documentation>Documentation</a></li>
            </ol>
          </section>
          <div id="directorynav" class="directorynav">
            <div id="dn-cola" class="column">
              <h3><a href="/discover/">Discover</a></h3>
              <ul>
                <li><a href="/macos/">macOS</a></li>
                <li><a href="/ios/">iOS</a></li>
                <li><a href="/watchos/">watchOS</a></li>
                <li><a href="/tvos/">tvOS</a></li>
                <li><a href="/safari/">Safari and Web</a></li>
                <li><a href="/games/">Games</a></li>
                <li><a href="/business/">Business</a></li>
                <li><a href="/education/">Education</a></li>
                <li><a href="/wwdc/">WWDC</a></li>
              </ul>
            </div>
            <div id="dn-colb" class="column">
              <h3><a href="/design/">Design</a></h3>
              <ul>
                <li><a href="/design/human-interface-guidelines/">Human Interface Guidelines</a></li>
                <li><a href="/design/resources/">Resources</a></li>
                <li><a href="/videos/design/">Videos</a></li>
                <li><a href="/design/awards/">Apple Design Awards</a></li>
                <li><a href="/accessibility/">Accessibility</a></li>
                <li><a href="/internationalization/">Internationalization</a></li>
                <li><a href="/accessories/">Accessories</a></li>
              </ul>
            </div>
            <div id="dn-colc" class="column">
              <h3><a href="/develop/">Develop</a></h3>
              <ul>
                <li><a href="/xcode/">Xcode</a></li>
                <li><a href="/swift/">Swift</a></li>
                <li><a href="/swift-playgrounds/">Swift Playgrounds</a></li>
                <li><a href="/testflight/">TestFlight</a></li>
                <li><a href="/documentation/">Documentation</a></li>
                <li><a href="/videos/">Videos</a></li>
                <li><a href="/download/">Downloads</a></li>
              </ul>
            </div>
            <div id="dn-cold" class="column">
              <h3><a href="/distribute/">Distribute</a></h3>
              <ul>
                <li><a href="/programs/">Developer Program</a></li>
                <li><a href="/app-store/">App Store</a></li>
                <li><a href="/app-store/review/">App Review</a></li>
                <li><a href="/macos/distribution/">Mac Software</a></li>
                <li><a href="/business/distribute/">Apps for Business</a></li>
                <li><a href="/safari/extensions/">Safari Extensions</a></li>
                <li><a href="/app-store/marketing/guidelines/">Marketing Resources</a></li>
                <li><a href="/softwarelicensing/">Trademark Licensing</a></li>
              </ul>
            </div>
            <div id="dn-cole" class="column">
              <h3><a href="/support/">Support</a></h3>
              <ul>
                <li><a href="https://forums.developer.apple.com">Developer Forums</a></li>
                <li><a href="/bug-reporting/">Bug Reporting</a></li>
                <li><a href="/terms/">License Agreements</a></li>
                <li><a href="/system-status/">System Status</a></li>
                <li><a href="/contact/">Contact Us</a></li>
              </ul>
              <h3><a href="/account/">Account</a></h3>
              <ul>
                <li><a href="/account/ios/certificate/">Certificates, IDs &amp; Profiles</a></li>
                <li><a href="https://appstoreconnect.apple.com/">App Store Connect</a></li>
              </ul>
            </div>
          </div>
        </nav>
        <div class="ac-gf-footer-legal">
          <div class="ac-gf-footer-news"> To receive the latest developer news, visit and subscribe to our <a href="/news/">News and Updates</a>.
          </div>
          <div class="ac-gf-footer-legal-copyright">Copyright © 2019 Apple Inc. All rights reserved.</div>
          <div class="ac-gf-footer-legal-links">
            <a href="https://www.apple.com/legal/internet-services/terms/site.html" class="first">Terms of Use</a>
            <a href="https://www.apple.com/privacy/privacy-policy/">Privacy Policy</a>
            <a href="/bug-reporting/">Report Bugs</a>
            <a href="/contact/submit/?subject=website-feedback">Feedback</a>
          </div>
          <div class="ac-gf-footer-language-links">
            <a href="/cn/" class="first">简体中文</a>
            <a href="/jp/">日本語</a>
            <a href="/kr/">한국어</a>
          </div>
        </div>
      </footer></section></div></div><script id="bootstrap-data" type="application/json">{"id":2942101,"title":{"content":"Using Vision in Real Time with ARKit"},"abstract":"<div><p>Manage Vision resources for efficient execution of a Core ML image classifier, and use SpriteKit to display image classifier output in AR.<\/p><\/div>","discussion":"<div><p>This sample app runs an <a href=\"\/documentation\/arkit\">ARKit<\/a> world-tracking session with content displayed in a SpriteKit view. The app uses the <a href=\"\/documentation\/vision\">Vision<\/a> framework to pass camera images to a <a href=\"\/documentation\/coreml\">Core ML<\/a> classifier model, displaying a label in the corner of the screen to indicate whether the classifier recognizes anything in view of the camera. After the classifier produces a label for the image, the user can tap the screen to place that text in AR world space.<\/p><aside class=\"aside aside-note\" role=\"note\"><p class=\"aside-name\">Note<\/p><p>The Core ML image classifier model doesn’t recognize and locate the 3D positions of objects. (In fact, the <code class=\"code-voice\"><span>Inceptionv3<\/span><\/code> model attempts only to identify an entire scene.) When the user taps the screen, the app adds a label at a real-world position corresponding to the tapped point. How closely a label appears to relate to the object it names depends on where the user taps.<\/p><\/aside><\/div><h3 id=\"3007540\">Implement the Vision\/Core ML Image Classifier<\/h3><div><p>The sample code’s <code class=\"code-voice\"><span>classification<wbr\/>Request<\/span><\/code> property, <code class=\"code-voice\"><span>classify<wbr\/>Current<wbr\/>Image()<\/span><\/code> method, and <code class=\"code-voice\"><span>process<wbr\/>Classifications(for:<wbr\/>error:)<\/span><\/code> method manage:<\/p><ul><li><p>A Core ML image-classifier model, loaded from an <code class=\"code-voice\"><span>mlmodel<\/span><\/code> file bundled with the app using the Swift API that Core ML generates for the model<\/p><\/li><li><p><a class=\"symbol-name\" href=\"\/documentation\/vision\/vncoremlrequest\"><code><span>VNCore<wbr\/>MLRequest<\/span><\/code><\/a> and <a class=\"symbol-name\" href=\"\/documentation\/vision\/vnimagerequesthandler\"><code><span>VNImage<wbr\/>Request<wbr\/>Handler<\/span><\/code><\/a> objects for passing image data to the model for evaluation<\/p><\/li><\/ul><p>For more details on using <a class=\"symbol-name\" href=\"\/documentation\/vision\/vnimagerequesthandler\"><code><span>VNImage<wbr\/>Request<wbr\/>Handler<\/span><\/code><\/a>, <a class=\"symbol-name\" href=\"\/documentation\/vision\/vncoremlrequest\"><code><span>VNCore<wbr\/>MLRequest<\/span><\/code><\/a>, and image classifier models, see the <a href=\"\/documentation\/vision\/classifying_images_with_vision_and_core_ml\">Classifying Images with Vision and Core ML<\/a> sample-code project.<\/p><\/div><h3 id=\"3007541\">Run the AR Session and Process Camera Images<\/h3><div><p>The sample <code class=\"code-voice\"><span>View<wbr\/>Controller<\/span><\/code> class manages the AR session and displays AR overlay content in a SpriteKit view. ARKit captures video frames from the camera and provides them to the view controller in the <a class=\"symbol-name\" href=\"\/documentation\/arkit\/arsessiondelegate\/2865611-session\"><code><span>session(_:<wbr\/>did<wbr\/>Update:)<\/span><\/code><\/a> method, which then calls the <code class=\"code-voice\"><span>classify<wbr\/>Current<wbr\/>Image()<\/span><\/code> method to run the Vision image classifier.<\/p><figure id=\"3007531\"><div class=\"formatted-content\"><div class=\"code-listing\"><pre class=\"code-source\" data-language=\"swift\"><code>func session(_ session: ARSession, didUpdate frame: ARFrame) {\n    \/\/ Do not enqueue other buffers for processing while another Vision task is still running.\n    \/\/ The camera stream has only a finite amount of buffers available; holding too many buffers for analysis would starve the camera.\n    guard currentBuffer == nil, case .normal = frame.camera.trackingState else {\n        return\n    }\n    \n    \/\/ Retain the image buffer for Vision processing.\n    self.currentBuffer = frame.capturedImage\n    classifyCurrentImage()\n}\n<\/code><\/pre><\/div><\/div><\/figure><p><\/p><\/div><h3 id=\"3007542\">Serialize Image Processing for Real-Time Performance<\/h3><div><p>The <code class=\"code-voice\"><span>classify<wbr\/>Current<wbr\/>Image()<\/span><\/code> method uses the view controller’s <code class=\"code-voice\"><span>current<wbr\/>Buffer<\/span><\/code> property to track whether Vision is currently processing an image before starting another Vision task.<\/p><figure id=\"3007533\"><div class=\"formatted-content\"><div class=\"code-listing\"><pre class=\"code-source\" data-language=\"swift\"><code>\/\/ Most computer vision tasks are not rotation agnostic so it is important to pass in the orientation of the image with respect to device.\nlet orientation = CGImagePropertyOrientation(UIDevice.current.orientation)\n\nlet requestHandler = VNImageRequestHandler(cvPixelBuffer: currentBuffer!, orientation: orientation)\nvisionQueue.async {\n    do {\n        \/\/ Release the pixel buffer when done, allowing the next buffer to be processed.\n        defer { self.currentBuffer = nil }\n        try requestHandler.perform([self.classificationRequest])\n    } catch {\n        print(&quot;Error: Vision request failed with error \\&quot;\\(error)\\&quot;&quot;)\n    }\n}\n<\/code><\/pre><\/div><\/div><\/figure><p><\/p><aside class=\"aside aside-important\" aria-label=\"important\"><p class=\"aside-name\">Important<\/p><p>Making sure only one buffer is being processed at a time ensures good performance. The camera recycles a finite pool of pixel buffers, so retaining too many buffers for processing could starve the camera and shut down the capture session. Passing multiple buffers to Vision for processing would slow down processing of each image, adding latency and reducing the amount of CPU and GPU overhead for rendering AR visualizations.<\/p><\/aside><p>In addition, the sample app enables the <a class=\"symbol-name\" href=\"\/documentation\/vision\/vnrequest\/2923480-usescpuonly\"><code><span>uses<wbr\/>CPUOnly<\/span><\/code><\/a> setting for its Vision request, freeing the GPU for use in rendering.<\/p><\/div><h3 id=\"3007543\">Visualize Results in AR<\/h3><div><p>The <code class=\"code-voice\"><span>process<wbr\/>Classifications(for:<wbr\/>error:)<\/span><\/code> method stores the best-match result label produced by the image classifier and displays it in the corner of the screen. The user can then tap in the AR scene to place that label at a real-world position. Placing a label requires two main steps.<\/p><p>First, a tap gesture recognizer fires the <code class=\"code-voice\"><span>place<wbr\/>Label<wbr\/>At<wbr\/>Location(sender:)<\/span><\/code> action. This method uses the ARKit <a class=\"symbol-name\" href=\"\/documentation\/arkit\/arskview\/2875733-hittest\"><code><span>hit<wbr\/>Test(_:<wbr\/>types:)<\/span><\/code><\/a> method to estimate the 3D real-world position corresponding to the tap, and adds an anchor to the AR session at that position.<\/p><figure id=\"3007535\"><div class=\"formatted-content\"><div class=\"code-listing\"><pre class=\"code-source\" data-language=\"swift\"><code>@IBAction func placeLabelAtLocation(sender: UITapGestureRecognizer) {\n    let hitLocationInView = sender.location(in: sceneView)\n    let hitTestResults = sceneView.hitTest(hitLocationInView, types: [.featurePoint, .estimatedHorizontalPlane])\n    if let result = hitTestResults.first {\n        \n        \/\/ Add a new anchor at the tap location.\n        let anchor = ARAnchor(transform: result.worldTransform)\n        sceneView.session.add(anchor: anchor)\n        \n        \/\/ Track anchor ID to associate text with the anchor after ARKit creates a corresponding SKNode.\n        anchorLabels[anchor.identifier] = identifierString\n    }\n}\n<\/code><\/pre><\/div><\/div><\/figure><p><\/p><p>Next, after ARKit automatically creates a SpriteKit node for the newly added anchor, the <a class=\"symbol-name\" href=\"\/documentation\/arkit\/arskviewdelegate\/2865588-view\"><code><span>view(_:<wbr\/>did<wbr\/>Add:<wbr\/>for:)<\/span><\/code><\/a> delegate method provides content for that node. In this case, the sample <code class=\"code-voice\"><span>Template<wbr\/>Label<wbr\/>Node<\/span><\/code> class creates a styled text label using the string provided by the image classifier.<\/p><figure id=\"3007536\"><div class=\"formatted-content\"><div class=\"code-listing\"><pre class=\"code-source\" data-language=\"swift\"><code>func view(_ view: ARSKView, didAdd node: SKNode, for anchor: ARAnchor) {\n    guard let labelText = anchorLabels[anchor.identifier] else {\n        fatalError(&quot;missing expected associated label for anchor&quot;)\n    }\n    let label = TemplateLabelNode(text: labelText)\n    node.addChild(label)\n}\n<\/code><\/pre><\/div><\/div><\/figure><p><\/p><\/div>","repository":{"downloadURL":"https:\/\/docs-assets.developer.apple.com\/published\/7da9756a21\/UsingVisionInRealTimeWithARKit.zip","checksum":"bdae02b7b0082ac23aac90e32f9f44e5e0ea6a69c1306e108fbc5021298a4467d22e87f09d39888b81b58c6a03e48230ad057e541d5b7926875f2c770ddbeca8"},"availability":[{"introduced":"11.3","current":"12.2","platform":"iOS"},{"introduced":"10.0","current":"10.2","platform":"Xcode"}],"containingGroup":[{"id":2952384,"role":"task","paths":[],"symbols":[{"id":2962794,"role":"sampleCode","paths":["documentation\/arkit\/creating_an_immersive_ar_experience_with_audio"],"abstract":"<div><p>Use sound effects and environmental sound layers to create an engaging AR experience.<\/p><\/div>","title":{"content":"Creating an Immersive AR Experience with Audio"}},{"id":2942101,"role":"sampleCode","paths":["documentation\/arkit\/using_vision_in_real_time_with_arkit"],"abstract":"<div><p>Manage Vision resources for efficient execution of a Core ML image classifier, and use SpriteKit to display image classifier output in AR.<\/p><\/div>","title":{"content":"Using Vision in Real Time with ARKit"}}],"title":{"content":"Related Technologies"}}],"modules":[{"title":{"content":"Vision"},"paths":["documentation\/vision"],"importStatement":"<import xml:space=\"preserve\"><keyWord>import<\/keyWord> Vision<\/import>","availability":[{"platform":"tvOS","introduced":"11.0"},{"platform":"macOS","introduced":"10.13"},{"platform":"iOS","introduced":"11.0"}]}],"role":"sampleCode","language":"swift","roleHeading":"Sample Code","languages":["occ","swift"],"variants":{"occ":{"paths":["documentation\/arkit\/using_vision_in_real_time_with_arkit"]},"swift":{"paths":["documentation\/arkit\/using_vision_in_real_time_with_arkit"]}},"pid":310635,"paths":["documentation\/arkit\/using_vision_in_real_time_with_arkit"],"hierarchy":[[{"id":2869388,"role":"collection","title":{"content":"ARKit"},"paths":["documentation\/arkit"]}]],"legalNotices":{"copyright":"Copyright &copy; 2019 Apple Inc. All rights reserved.","termsOfUse":"https:\/\/www.apple.com\/legal\/internet-services\/terms\/site.html","privacyPolicy":"https:\/\/www.apple.com\/privacy\/privacy-policy"}}</script><script src="/documentation/__assets/TopicDetail-fe7d3f3d.js"></script><script src="/documentation/__assets/analytics-8acae80a.js"></script></body></html>